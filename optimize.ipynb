{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import cma\n",
    "# from eval import play\n",
    "import random\n",
    "\n",
    "from gan.config import BaseConfig,ZeldaConfig,MarioConfig\n",
    "from gan.models.general_models import Generator\n",
    "from play_rl.zelda_astar import play_astar\n",
    "from gan.utils import tensor_to_level_str,check_playable\n",
    "from gan.level_visualizer import GVGAILevelVisualizer\n",
    "from gan.game.env import Game\n",
    "from gan.game.zelda import Zelda\n",
    "from play_rl.wrappers import GridGame\n",
    "from play_rl.policy import Policy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Zelda('v1')\n",
    "config = ZeldaConfig()\n",
    "config.set_env(game)\n",
    "def get_model(game: Game, config: BaseConfig):\n",
    "    # reproducible settings\n",
    "    random.seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    torch.manual_seed(config.seed)\n",
    "    torch.cuda.manual_seed(config.seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    device = torch.device('cpu')\n",
    "    # device = torch.device(\n",
    "    #     f'cuda:{config.gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
    "    generator = Generator(\n",
    "        isize=game.input_shape[1], nz=config.latent_size, nc=game.input_shape[\n",
    "            0], ngf=config.generator_filters, self_attention=config.use_self_attention_g, n_extra_layers=config.extra_layers_g\n",
    "    ).to(device)\n",
    "    return generator\n",
    "level_visualizer = GVGAILevelVisualizer(game)\n",
    "generator = get_model(game,config)\n",
    "model_save_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-68\"\n",
    "model_dict = torch.load(os.path.join(model_save_path, \"latest.tar\"))\n",
    "generator.load_state_dict(model_dict['generator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=520x196>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f1(level_str):\n",
    "    wall = 0\n",
    "    enemy = 0\n",
    "    for i, s in enumerate(level_str):\n",
    "        for j, c in enumerate(s):\n",
    "            if c == 'w':\n",
    "                wall += 1\n",
    "            if c in ['1', '2', '3']:\n",
    "                enemy += 1\n",
    "    return - wall - 5 * enemy\n",
    "\n",
    "\n",
    "def f2(level_str):\n",
    "    wall = 0\n",
    "    enemy = 0\n",
    "    for i, s in enumerate(level_str):\n",
    "        for j, c in enumerate(s):\n",
    "            if c == 'w':\n",
    "                wall += 1\n",
    "            if c in ['1', '2', '3']:\n",
    "                enemy += 1\n",
    "    return wall + 5 * enemy\n",
    "\n",
    "\n",
    "def f3(level_str):\n",
    "    wall = 0\n",
    "    enemy = 0\n",
    "    for i, s in enumerate(level_str):\n",
    "        for j, c in enumerate(s):\n",
    "            if c == 'w':\n",
    "                wall += 1\n",
    "            if c in ['1', '2', '3']:\n",
    "                enemy += 1\n",
    "    return abs(wall - 100) + 3*abs(enemy - 3)\n",
    "\n",
    "# # env = GridGame(config.env_name, 200, env_def.state_shape)\n",
    "# # actor = Policy(env.observation_space.shape, env.action_space,base_kwargs={\"recurrent\": True})\n",
    "# # actor.load_state_dict(torch.load('/root/mnt/GVGAI-GAN/play_rl/checkpoints/ppo/zelda_20220825102126.pt'))\n",
    "\n",
    "def fitnessf1(x: torch.Tensor):\n",
    "    x = np.array(x)\n",
    "    latent = torch.FloatTensor(x).view(1,-1)\n",
    "    level,_ = generator(latent)\n",
    "    level_str = game.level_tensor_to_strs(level)\n",
    "    playable = game.check_playable(level_str[0])\n",
    "    if not playable:\n",
    "        return 1000\n",
    "    # reward,step,_ = play(level_str[0],env=env,actor=actor)\n",
    "    # reward, step, _ = play_astar(level_str[0], env=env)\n",
    "    # return -(reward*100+step)\n",
    "    ev = f1(level_str)\n",
    "    return ev\n",
    "\n",
    "\n",
    "def fitnessf2(x: torch.Tensor):\n",
    "    x = np.array(x)\n",
    "    latent = torch.FloatTensor(x).view(1,-1)\n",
    "    level,_ = generator(latent)\n",
    "    level_str = game.level_tensor_to_strs(level)\n",
    "    playable = game.check_playable(level_str[0])\n",
    "    if not playable:\n",
    "        return 1000\n",
    "    ev = f2(level_str)\n",
    "    return ev\n",
    "\n",
    "\n",
    "def fitnessf3(x: torch.Tensor):\n",
    "    x = np.array(x)\n",
    "    latent = torch.FloatTensor(x).view(1, -1)\n",
    "    level, _ = generator(latent)\n",
    "    level_str = game.level_tensor_to_strs(level)\n",
    "    playable = game.check_playable(level_str[0])\n",
    "    if not playable:\n",
    "        return 1000\n",
    "    ev = f3(level_str)\n",
    "    return ev\n",
    "\n",
    "\n",
    "\n",
    "def show(x):\n",
    "    latent = torch.FloatTensor(x).view(1, -1)\n",
    "    p_level,_ = generator(latent)\n",
    "    level_strs = game.level_tensor_to_strs(p_level)\n",
    "    p_level_img = np.array(level_visualizer.draw_level(level_strs[0]))\n",
    "    image = Image.fromarray(p_level_img)\n",
    "    image.show()\n",
    "\n",
    "\n",
    "def show2(x,x2):\n",
    "    latent1,latent2 = torch.FloatTensor(x).view(1, -1),torch.FloatTensor(x2).view(1,-1)\n",
    "    p_level,_ = generator(latent1)\n",
    "    level_strs = game.level_tensor_to_strs(p_level)\n",
    "    p_level_img1 = np.array(level_visualizer.draw_level(level_strs[0]))\n",
    "    p_level,_ = generator(latent2)\n",
    "    level_strs = game.level_tensor_to_strs(p_level)\n",
    "    p_level_img2 = np.array(level_visualizer.draw_level(level_strs[0]))\n",
    "    concated = np.concatenate([p_level_img1,p_level_img2],axis=1)\n",
    "    image = Image.fromarray(concated)\n",
    "    image.show()\n",
    "\n",
    "    \n",
    "x = torch.randn(config.latent_size)\n",
    "es = cma.CMAEvolutionStrategy(x.tolist(),0.5,{'verbose':-9})\n",
    "# print(cma.CMAOptions('verb'))\n",
    "# es.optimize(fitness,iterations=30,min_iterations=30)\n",
    "es.optimize(fitnessf2,iterations=100,min_iterations=100)\n",
    "best = np.array(es.best.get()[0])\n",
    "# print(\"INIT: \", np.array(x.tolist()))\n",
    "# print(\"BEST: \", best)\n",
    "print(\"Fitness: \", fitnessf2(best))\n",
    "show2(x,torch.FloatTensor(best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(generator,fitness):\n",
    "    scores = []\n",
    "\n",
    "    wall_and_enemy_scores = []\n",
    "    wall_and_enemy_changes = []\n",
    "\n",
    "    playables = []\n",
    "    playable_levels = []\n",
    "    def check_level_hamming(level1: str, level2: str):\n",
    "        hit = 0\n",
    "        for c1, c2 in zip(level1, level2):\n",
    "            if c1 == \"\\n\":\n",
    "                continue\n",
    "            if c1 != c2:\n",
    "                hit += 1\n",
    "        return hit\n",
    "\n",
    "    def count_wall_and_enemy(level_str: str):\n",
    "        hit = 0\n",
    "        for j, c in enumerate(level_str):\n",
    "            if c == 'w':\n",
    "                hit += 1\n",
    "            if c in ['1', '2', '3']:\n",
    "                hit += 5\n",
    "        return hit\n",
    "\n",
    "    for i in range(50):\n",
    "        x = torch.randn(config.latent_size).view(1,-1)\n",
    "        es = cma.CMAEvolutionStrategy(x.tolist(), 0.5, {'verbose': -9})\n",
    "        es.optimize(fitness,iterations=100,min_iterations=100)\n",
    "        best = np.array(es.best.get()[0])\n",
    "        print(\"Fitness: \", fitness(best))\n",
    "        level_first,_ = generator(x)\n",
    "        level_str_first = game.level_tensor_to_strs(level_first)\n",
    "        wall_and_enemy_first = count_wall_and_enemy(level_str_first[0])\n",
    "        level_target,_ = generator(torch.FloatTensor(best).view(1,-1))\n",
    "        level_str_target = game.level_tensor_to_strs(level_target)\n",
    "        wall_and_enemy_target = count_wall_and_enemy(level_str_target[0])\n",
    "        playable = game.check_playable(level_str_target[0])\n",
    "        playables.append(1 if playable else 0)\n",
    "        if playable:\n",
    "            scores.append(fitness(best))\n",
    "            wall_and_enemy_scores.append(wall_and_enemy_target)\n",
    "            wall_and_enemy_changes.append(wall_and_enemy_target-wall_and_enemy_first)\n",
    "            playable_levels.append(level_str_target[0])\n",
    "        # show(torch.FloatTensor(best))\n",
    "\n",
    "    hamming_dist_sum = 0\n",
    "    n = 0\n",
    "    for i in range(len(playable_levels)):\n",
    "        for j in range(len(playable_levels)):\n",
    "            if i==j: \n",
    "                continue\n",
    "            hamming_dist_sum += check_level_hamming(playable_levels[i], playable_levels[j])\n",
    "            n+=1\n",
    "\n",
    "    print(f\"mean score:{np.array(scores).mean()}\")\n",
    "    print(f\"mean counts:{np.array(wall_and_enemy_scores).mean()}\")\n",
    "    print(f\"mean changes:{np.array(wall_and_enemy_changes).mean()}\")\n",
    "    print(f\"mean playability:{np.array(playables).mean()}\")\n",
    "    print(f\"mean hamming dist:{hamming_dist_sum/n}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  -105\n",
      "Fitness:  -124\n",
      "Fitness:  -117\n",
      "Fitness:  -105\n",
      "Fitness:  -113\n",
      "Fitness:  -112\n",
      "Fitness:  -116\n",
      "Fitness:  -111\n",
      "Fitness:  -102\n",
      "Fitness:  -120\n",
      "Fitness:  -123\n",
      "Fitness:  -106\n",
      "Fitness:  -118\n",
      "Fitness:  -116\n",
      "Fitness:  -113\n",
      "Fitness:  -128\n",
      "Fitness:  -105\n",
      "Fitness:  -115\n",
      "Fitness:  -119\n",
      "Fitness:  -121\n",
      "Fitness:  -125\n",
      "Fitness:  -109\n",
      "Fitness:  -105\n",
      "Fitness:  -110\n",
      "Fitness:  -117\n",
      "Fitness:  -117\n",
      "Fitness:  -115\n",
      "Fitness:  -115\n",
      "Fitness:  -112\n",
      "Fitness:  -116\n",
      "Fitness:  -114\n",
      "Fitness:  -112\n",
      "Fitness:  -112\n",
      "Fitness:  -119\n",
      "Fitness:  -101\n",
      "Fitness:  -106\n",
      "Fitness:  -117\n",
      "Fitness:  -109\n",
      "Fitness:  -114\n",
      "Fitness:  -115\n",
      "Fitness:  -112\n",
      "Fitness:  -116\n",
      "Fitness:  -120\n",
      "Fitness:  -105\n",
      "Fitness:  -116\n",
      "Fitness:  -119\n",
      "Fitness:  -109\n",
      "Fitness:  -118\n",
      "Fitness:  -116\n",
      "Fitness:  -103\n",
      "mean score:-113.66\n",
      "mean counts:113.66\n",
      "mean changes:27.6\n",
      "mean playability:1.0\n",
      "mean hamming dist:38.46775510204082\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-71/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  -90\n",
      "Fitness:  -95\n",
      "Fitness:  -96\n",
      "Fitness:  -96\n",
      "Fitness:  -94\n",
      "Fitness:  -93\n",
      "Fitness:  -105\n",
      "Fitness:  -94\n",
      "Fitness:  -104\n",
      "Fitness:  -95\n",
      "Fitness:  -96\n",
      "Fitness:  -104\n",
      "Fitness:  -82\n",
      "Fitness:  -92\n",
      "Fitness:  -88\n",
      "Fitness:  -88\n",
      "Fitness:  -90\n",
      "Fitness:  -83\n",
      "Fitness:  -94\n",
      "Fitness:  -86\n",
      "Fitness:  -94\n",
      "Fitness:  -104\n",
      "Fitness:  -95\n",
      "Fitness:  -93\n",
      "Fitness:  -94\n",
      "Fitness:  -84\n",
      "Fitness:  -104\n",
      "Fitness:  -106\n",
      "Fitness:  -94\n",
      "Fitness:  -99\n",
      "Fitness:  -103\n",
      "Fitness:  -97\n",
      "Fitness:  -97\n",
      "Fitness:  -94\n",
      "Fitness:  -90\n",
      "Fitness:  -92\n",
      "Fitness:  -100\n",
      "Fitness:  -95\n",
      "Fitness:  -105\n",
      "Fitness:  -82\n",
      "Fitness:  -92\n",
      "Fitness:  -88\n",
      "Fitness:  -90\n",
      "Fitness:  -95\n",
      "Fitness:  -92\n",
      "Fitness:  -87\n",
      "Fitness:  -100\n",
      "Fitness:  -90\n",
      "Fitness:  -90\n",
      "Fitness:  -104\n",
      "mean score:-94.3\n",
      "mean counts:94.3\n",
      "mean changes:19.4\n",
      "mean playability:1.0\n",
      "mean hamming dist:39.4269387755102\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-68/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  64\n",
      "Fitness:  61\n",
      "Fitness:  66\n",
      "Fitness:  63\n",
      "Fitness:  65\n",
      "Fitness:  71\n",
      "Fitness:  65\n",
      "Fitness:  70\n",
      "Fitness:  62\n",
      "Fitness:  62\n",
      "Fitness:  58\n",
      "Fitness:  62\n",
      "Fitness:  66\n",
      "Fitness:  65\n",
      "Fitness:  63\n",
      "Fitness:  68\n",
      "Fitness:  63\n",
      "Fitness:  68\n",
      "Fitness:  62\n",
      "Fitness:  65\n",
      "Fitness:  65\n",
      "Fitness:  59\n",
      "Fitness:  64\n",
      "Fitness:  61\n",
      "Fitness:  70\n",
      "Fitness:  63\n",
      "Fitness:  63\n",
      "Fitness:  61\n",
      "Fitness:  65\n",
      "Fitness:  67\n",
      "Fitness:  63\n",
      "Fitness:  65\n",
      "Fitness:  58\n",
      "Fitness:  65\n",
      "Fitness:  62\n",
      "Fitness:  59\n",
      "Fitness:  74\n",
      "Fitness:  64\n",
      "Fitness:  69\n",
      "Fitness:  69\n",
      "Fitness:  66\n",
      "Fitness:  64\n",
      "Fitness:  61\n",
      "Fitness:  62\n",
      "Fitness:  59\n",
      "Fitness:  71\n",
      "Fitness:  59\n",
      "Fitness:  60\n",
      "Fitness:  63\n",
      "Fitness:  66\n",
      "mean score:64.12\n",
      "mean counts:64.12\n",
      "mean changes:-20.74\n",
      "mean playability:1.0\n",
      "mean hamming dist:21.81142857142857\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-71/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  63\n",
      "Fitness:  62\n",
      "Fitness:  62\n",
      "Fitness:  58\n",
      "Fitness:  62\n",
      "Fitness:  64\n",
      "Fitness:  61\n",
      "Fitness:  62\n",
      "Fitness:  58\n",
      "Fitness:  65\n",
      "Fitness:  64\n",
      "Fitness:  60\n",
      "Fitness:  56\n",
      "Fitness:  58\n",
      "Fitness:  55\n",
      "Fitness:  59\n",
      "Fitness:  62\n",
      "Fitness:  58\n",
      "Fitness:  62\n",
      "Fitness:  65\n",
      "Fitness:  61\n",
      "Fitness:  56\n",
      "Fitness:  62\n",
      "Fitness:  59\n",
      "Fitness:  62\n",
      "Fitness:  58\n",
      "Fitness:  60\n",
      "Fitness:  55\n",
      "Fitness:  66\n",
      "Fitness:  58\n",
      "Fitness:  57\n",
      "Fitness:  58\n",
      "Fitness:  61\n",
      "Fitness:  58\n",
      "Fitness:  62\n",
      "Fitness:  60\n",
      "Fitness:  61\n",
      "Fitness:  65\n",
      "Fitness:  59\n",
      "Fitness:  57\n",
      "Fitness:  55\n",
      "Fitness:  60\n",
      "Fitness:  55\n",
      "Fitness:  55\n",
      "Fitness:  55\n",
      "Fitness:  65\n",
      "Fitness:  56\n",
      "Fitness:  57\n",
      "Fitness:  63\n",
      "Fitness:  59\n",
      "mean score:59.82\n",
      "mean counts:59.82\n",
      "mean changes:-16.08\n",
      "mean playability:1.0\n",
      "mean hamming dist:13.311836734693877\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-68/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-71/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-68/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  49\n",
      "Fitness:  64\n",
      "Fitness:  81\n",
      "Fitness:  4\n",
      "Fitness:  25\n",
      "Fitness:  1\n",
      "Fitness:  16\n",
      "Fitness:  64\n",
      "Fitness:  49\n",
      "Fitness:  49\n",
      "Fitness:  100\n",
      "Fitness:  16\n",
      "Fitness:  81\n",
      "Fitness:  25\n",
      "Fitness:  36\n",
      "Fitness:  81\n",
      "Fitness:  49\n",
      "Fitness:  25\n",
      "Fitness:  16\n",
      "Fitness:  100\n",
      "Fitness:  49\n",
      "Fitness:  144\n",
      "Fitness:  81\n",
      "Fitness:  36\n",
      "Fitness:  9\n",
      "Fitness:  144\n",
      "Fitness:  9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/mnt/pcg/GVGAI-GAN/optimize.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m load_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(model_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m generator\u001b[39m.\u001b[39mload_state_dict(load_model[\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m check(generator, fitnessf2)\n",
      "\u001b[1;32m/root/mnt/pcg/GVGAI-GAN/optimize.ipynb Cell 11\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(generator, fitness)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(config\u001b[39m.\u001b[39mlatent_size)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m es \u001b[39m=\u001b[39m cma\u001b[39m.\u001b[39mCMAEvolutionStrategy(x\u001b[39m.\u001b[39mtolist(), \u001b[39m0.5\u001b[39m, {\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m})\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m es\u001b[39m.\u001b[39;49moptimize(fitness,iterations\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,min_iterations\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)        \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# es.optimize(fitness)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m best \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(es\u001b[39m.\u001b[39mbest\u001b[39m.\u001b[39mget()[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/cma/interfaces.py:208\u001b[0m, in \u001b[0;36mOOOptimizer.optimize\u001b[0;34m(self, objective_fct, maxfun, iterations, min_iterations, args, verb_disp, callback, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mask()  \u001b[39m# deliver candidate solutions\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# fitvals = [objective_fct(x, *args) for x in X]\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m fitvals \u001b[39m=\u001b[39m eval_all(X, args\u001b[39m=\u001b[39;49margs)\n\u001b[1;32m    209\u001b[0m cevals \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(fitvals)\n\u001b[1;32m    210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell(X, fitvals)  \u001b[39m# all the work is done here\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/cma/optimization_tools.py:284\u001b[0m, in \u001b[0;36mEvalParallel2.__call__\u001b[0;34m(self, solutions, fitness_function, args, timeout)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fitness_function` was never given, must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m passed in `__init__` or `__call__`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool:\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m [fitness_function(x, \u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m solutions]\n\u001b[1;32m    285\u001b[0m warning_str \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m`fitness_function` must be a function, not a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39m `lambda` or an instancemethod, in order to work with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39m `multiprocessing` under Python 2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/cma/optimization_tools.py:284\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fitness_function` was never given, must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m passed in `__init__` or `__call__`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool:\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m [fitness_function(x, \u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m solutions]\n\u001b[1;32m    285\u001b[0m warning_str \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m`fitness_function` must be a function, not a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39m `lambda` or an instancemethod, in order to work with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39m `multiprocessing` under Python 2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;32m/root/mnt/pcg/GVGAI-GAN/optimize.ipynb Cell 11\u001b[0m in \u001b[0;36mfitnessf2\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m latent \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(x)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m level,_ \u001b[39m=\u001b[39m generator(latent)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m level_str \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mlevel_tensor_to_strs(level)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f732d74616b617461403137322e32312e36342e313931227d7d/root/mnt/pcg/GVGAI-GAN/optimize.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m playable \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mcheck_playable(level_str[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mnt/pcg/GVGAI-GAN/gan/models/general_models.py:356\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, input, label)\u001b[0m\n\u001b[1;32m    354\u001b[0m hiddens \u001b[39m=\u001b[39m []\n\u001b[1;32m    355\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmods:\n\u001b[0;32m--> 356\u001b[0m     hidden \u001b[39m=\u001b[39m module(hidden)\n\u001b[1;32m    357\u001b[0m     hiddens\u001b[39m.\u001b[39mappend(hidden)\n\u001b[1;32m    358\u001b[0m output \u001b[39m=\u001b[39m hidden\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/activation.py:1406\u001b[0m, in \u001b[0;36mSoftmax2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m   1405\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSoftmax2d requires a 3D or 4D tensor as input\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1406\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msoftmax(\u001b[39minput\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m3\u001b[39;49m, _stacklevel\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/functional.py:1834\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1833\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1834\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[1;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1836\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-74/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  -127\n",
      "Fitness:  -126\n",
      "Fitness:  -128\n",
      "Fitness:  -137\n",
      "Fitness:  -127\n",
      "Fitness:  -118\n",
      "Fitness:  -126\n",
      "Fitness:  -127\n",
      "Fitness:  -114\n",
      "Fitness:  -115\n",
      "Fitness:  -112\n",
      "Fitness:  -133\n",
      "Fitness:  -126\n",
      "Fitness:  -145\n",
      "Fitness:  -140\n",
      "Fitness:  -124\n",
      "Fitness:  -132\n",
      "Fitness:  -119\n",
      "Fitness:  -116\n",
      "Fitness:  -119\n",
      "Fitness:  -130\n",
      "Fitness:  -131\n",
      "Fitness:  -132\n",
      "Fitness:  -123\n",
      "Fitness:  -122\n",
      "Fitness:  -123\n",
      "Fitness:  -118\n",
      "Fitness:  -137\n",
      "Fitness:  -147\n",
      "Fitness:  -134\n",
      "Fitness:  -129\n",
      "Fitness:  -125\n",
      "Fitness:  -126\n",
      "Fitness:  -131\n",
      "Fitness:  -121\n",
      "Fitness:  -126\n",
      "Fitness:  -127\n",
      "Fitness:  -125\n",
      "Fitness:  -129\n",
      "Fitness:  -131\n",
      "Fitness:  -136\n",
      "Fitness:  -134\n",
      "Fitness:  -124\n",
      "Fitness:  -143\n",
      "Fitness:  -117\n",
      "Fitness:  -127\n",
      "Fitness:  -136\n",
      "Fitness:  -127\n",
      "Fitness:  -125\n",
      "Fitness:  -133\n",
      "mean score:-127.6\n",
      "mean counts:127.6\n",
      "mean changes:34.26\n",
      "mean playability:1.0\n",
      "mean hamming dist:46.93061224489796\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/new-74/latest.tar\"\n",
    "load_model = torch.load(model_path)\n",
    "generator.load_state_dict(load_model[\"generator\"])\n",
    "check(generator, fitnessf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline\n",
    "# model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/none-700/latest.tar\"\n",
    "# load_model = torch.load(model_path)\n",
    "# generator.load_state_dict(load_model[\"generator\"])\n",
    "# check(generator, fitnessf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline\n",
    "# model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/none-700/latest.tar\"\n",
    "# load_model = torch.load(model_path)\n",
    "# generator.load_state_dict(load_model[\"generator\"])\n",
    "# check(generator, fitnessf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ours2\n",
    "# model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/none-714/latest.tar\"\n",
    "# load_model = torch.load(model_path)\n",
    "# generator.load_state_dict(load_model[\"generator\"])\n",
    "\n",
    "# check(generator,fitnessf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ours2\n",
    "# model_path = \"/root/mnt/pcg/GVGAI-GAN/gan/checkpoints/zelda_v1/none-714/latest.tar\"\n",
    "# load_model = torch.load(model_path)\n",
    "# generator.load_state_dict(load_model[\"generator\"])\n",
    "# check(generator, fitnessf2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6f04e54c30bdab06014272fe7a39801e1ba23455c10166a981ed4409abbe2cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('3.8.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6f04e54c30bdab06014272fe7a39801e1ba23455c10166a981ed4409abbe2cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
